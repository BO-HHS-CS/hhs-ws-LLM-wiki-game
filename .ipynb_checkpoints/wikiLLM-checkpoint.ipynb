{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9nA9OrmewFzA",
    "outputId": "69f14120-849a-4444-a905-f2e848d3edfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  python3-pip-whl python3-setuptools-whl\n",
      "The following NEW packages will be installed:\n",
      "  python3-pip-whl python3-setuptools-whl python3.10-venv\n",
      "0 upgraded, 3 newly installed, 0 to remove and 31 not upgraded.\n",
      "Need to get 2,473 kB of archives.\n",
      "After this operation, 2,884 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-pip-whl all 22.0.2+dfsg-1ubuntu0.4 [1,680 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-setuptools-whl all 59.6.0-1.2ubuntu0.22.04.1 [788 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3.10-venv amd64 3.10.12-1~22.04.3 [5,716 B]\n",
      "Fetched 2,473 kB in 0s (6,652 kB/s)\n",
      "Selecting previously unselected package python3-pip-whl.\n",
      "(Reading database ... 121730 files and directories currently installed.)\n",
      "Preparing to unpack .../python3-pip-whl_22.0.2+dfsg-1ubuntu0.4_all.deb ...\n",
      "Unpacking python3-pip-whl (22.0.2+dfsg-1ubuntu0.4) ...\n",
      "Selecting previously unselected package python3-setuptools-whl.\n",
      "Preparing to unpack .../python3-setuptools-whl_59.6.0-1.2ubuntu0.22.04.1_all.deb ...\n",
      "Unpacking python3-setuptools-whl (59.6.0-1.2ubuntu0.22.04.1) ...\n",
      "Selecting previously unselected package python3.10-venv.\n",
      "Preparing to unpack .../python3.10-venv_3.10.12-1~22.04.3_amd64.deb ...\n",
      "Unpacking python3.10-venv (3.10.12-1~22.04.3) ...\n",
      "Setting up python3-setuptools-whl (59.6.0-1.2ubuntu0.22.04.1) ...\n",
      "Setting up python3-pip-whl (22.0.2+dfsg-1ubuntu0.4) ...\n",
      "Setting up python3.10-venv (3.10.12-1~22.04.3) ...\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.1.4-py3-none-any.whl (803 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.6/803.6 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting replicate\n",
      "  Downloading replicate-0.23.1-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
      "Collecting python-decouple\n",
      "  Downloading python_decouple-3.8-py3-none-any.whl (9.9 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.24)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
      "  Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Collecting langchain-community<0.1,>=0.0.14 (from langchain)\n",
      "  Downloading langchain_community-0.0.16-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting langchain-core<0.2,>=0.1.16 (from langchain)\n",
      "  Downloading langchain_core-0.1.17-py3-none-any.whl (235 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting langsmith<0.1,>=0.0.83 (from langchain)\n",
      "  Downloading langsmith-0.0.84-py3-none-any.whl (53 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.14)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
      "Collecting httpx<1,>=0.21.0 (from replicate)\n",
      "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from replicate) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from replicate) (4.5.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (3.7.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (2023.11.17)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.21.0->replicate)\n",
      "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (3.6)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (1.3.0)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.21.0->replicate)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
      "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.21.0->replicate) (1.2.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: python-decouple, mypy-extensions, marshmallow, jsonpointer, h11, typing-inspect, langsmith, jsonpatch, httpcore, langchain-core, httpx, dataclasses-json, replicate, langchain-community, langchain\n",
      "Successfully installed dataclasses-json-0.6.3 h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.4 langchain-community-0.0.16 langchain-core-0.1.17 langsmith-0.0.84 marshmallow-3.20.2 mypy-extensions-1.0.0 python-decouple-3.8 replicate-0.23.1 typing-inspect-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!apt install python3.10-venv\n",
    "!python3 -m venv venv\n",
    "\n",
    "!source venv/bin/activate\n",
    "\n",
    "!pip install langchain replicate pillow python-decouple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "bmHHkLcdEbdo"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from decouple import config\n",
    "from langchain.llms import Replicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "xim8-SF8wf4V"
   },
   "outputs": [],
   "source": [
    "with open(\".env\", 'w') as file:\n",
    "    file.write(f\"REPLICATE_API_TOKEN=r8_WbvPP4dFYKKMmRXX0Hwod8RVGKgOFji34E7qy\")\n",
    "\n",
    "# load in environment variables\n",
    "REPLICATE_API_TOKEN = config(\"REPLICATE_API_TOKEN\")\n",
    "os.environ[\"REPLICATE_API_TOKEN\"] = REPLICATE_API_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "NP-CxKsDEjvJ"
   },
   "outputs": [],
   "source": [
    "llm: Replicate = Replicate(\n",
    "    model=\"meta/codellama-34b-instruct:eeb928567781f4e90d2aba57a51baef235de53f907c214a4ab42adabf5bb9736\",\n",
    "    model_kwargs={\"system_prompt\": \"\", \"temperature\": 0.75, \"max_length\": 500, \"top_p\": 1}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "O_UMcAa_6okj"
   },
   "outputs": [],
   "source": [
    "list_of_topics = \"s, Hawaii, Botany, Ferdinand_von_Mueller, Chemist, Politician, John_Macadam, Philosophical_Institute_of_Victoria, Evergreen, Genus, Whorl_(botany), Lanceolate, Obovate, Elliptic, Leaf_shape, Raceme, Tepal, Follicle_(fruit), Seed, Newton_(unit), Hazelnut, Aluminium, Vickers_hardness_test, Glycoside#Cyanogenic_glycosides, Disjunct_distribution, Morphology_(biology), Grafting, Proteaceae, Phytophthora, Macadamia_integrifolia, Macadamia_tetraphylla, Macadamia_tetraphylla, South_Africa, Mediterranean_climate, Temperate_climate, Tropical_climate, Lismore,_New_South_Wales, Macadamia_tetraphylla, Hawaii, William_H._Purvis, Kapulena, Queensland, Gympie, Banana, Carbohydrate, Fat, Protein_(nutrient), Kilocalories, Daily_Value, Essential_nutrients, Thiamine, Vitamin_B6, B_vitamins, Manganese, Iron, Magnesium, Phosphorus, Almond, Cashew, Monounsaturated_fat, Monounsaturated_fat, Omega-7_fatty_acid, Palmitoleic_acid, Food_allergy, Tree_nut_allergy, United_States, Oral_allergy_syndrome, Urticaria, Angioedema, Asthma, Anaphylaxis, Coconut, Walnut, Hazelnut, Cashew, Epinephrine_auto-injector, Toxic, Ingestion, Weakness, Ornamental_plant, Larva, Lepidoptera, Batrachedra, Wikipedia:Citation_needed, Hyacinth_macaw, Parrot\"\n",
    "num_of_topics = 3\n",
    "goal_topic = \"Computer_science\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "um_jGiWnFAAa",
    "outputId": "7ec2e8f8-8ac2-4b53-e25f-6d505d119c6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Newton_(unit), Hazelnut, Aluminium\n"
     ]
    }
   ],
   "source": [
    "prompt: str = f\"\"\"\n",
    "From the following list of topics [{list_of_topics}], pick up to {num_of_topics} that relate most closely about {goal_topic}.\n",
    "Your response should include no explanation. The list of topics MUST be formatted in square brackets [] separated by commas.\n",
    "DO NOT respond in bullet point lists or numbered lists.\n",
    "The wording of the topics (including the underscores) must be exactly as given.\n",
    "\"\"\"\n",
    "\n",
    "response: str = llm(prompt=prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "aQn1JwT3FD4W"
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "KQVqGlbuxuRZ"
   },
   "outputs": [],
   "source": [
    "class WikiGame:\n",
    "    def __init__(self, spread_constant=10):\n",
    "        self.visited_topics = []\n",
    "        self.path = []\n",
    "        # Determines how many links it grabs from each wikipedia page\n",
    "        self.spread_constant = spread_constant\n",
    "\n",
    "    def start_game(self, llm=False, system_prompt=\"\", temperature=0.75, max_length=500, top_p=1):\n",
    "        # Asks user for start and end links\n",
    "        start_link = input(\"What is the start link?:\")\n",
    "        self.start_topic = re.findall(\"\\/wiki\\/([^#]*)\", start_link)[0]\n",
    "        goal_link = input(\"What is the goal link?:\")\n",
    "        self.goal_topic = re.findall(\"\\/wiki\\/([^#]*)\", goal_link)[0]\n",
    "\n",
    "        if llm:\n",
    "            self.instantiate_llm(system_prompt=system_prompt, temperature=temperature, max_length=max_length, top_p=top_p)\n",
    "\n",
    "        print(\"Search Started\")\n",
    "        start_time = time.time()\n",
    "        # Begins Breadth First Search\n",
    "        discovered_path = self.bfs_search(llm=llm)\n",
    "\n",
    "        print(\"\\nPath Found:\")\n",
    "        for topic in discovered_path:\n",
    "            print(topic)\n",
    "        print(f\"\\nTime taken: {time.time()-start_time:.2f} seconds\")\n",
    "\n",
    "    def instantiate_llm(self, system_prompt=\"\", temperature=0.75, max_length=500, top_p=1):\n",
    "        self.llm: Replicate = Replicate(\n",
    "            model=\"meta/codellama-34b-instruct:eeb928567781f4e90d2aba57a51baef235de53f907c214a4ab42adabf5bb9736\",\n",
    "            model_kwargs={\"system_prompt\": system_prompt, \"temperature\": temperature, \"max_length\": max_length, \"top_p\": top_p}\n",
    "        )\n",
    "\n",
    "    def write_token_file(self, token):\n",
    "        with open(\".env\", 'w') as file:\n",
    "            file.write(f\"REPLICATE_API_TOKEN={token}\")\n",
    "        # load in environment variables\n",
    "        REPLICATE_API_TOKEN = config(\"REPLICATE_API_TOKEN\")\n",
    "        os.environ[\"REPLICATE_API_TOKEN\"] = REPLICATE_API_TOKEN\n",
    "\n",
    "    def bfs_search(self, llm=False):\n",
    "        # Begins queue\n",
    "        queue = [(-1, self.start_topic)]\n",
    "\n",
    "        while queue:\n",
    "            # Takes first topic in queue\n",
    "            parent_index, parent_topic = queue.pop(0)\n",
    "\n",
    "            if parent_topic not in self.visited_topics:\n",
    "                self.visited_topics.append(parent_topic)\n",
    "                self.path.append(parent_index)\n",
    "\n",
    "                # Gets topics from the Wikpedia page\n",
    "                soup = self.make_soup(parent_topic)\n",
    "                if llm:\n",
    "                    topics_found = self.llm_pick_topics(soup)\n",
    "                else:\n",
    "                    topics_found = self.find_new_topics(soup)\n",
    "\n",
    "                print(f\"{parent_index} From {self.visited_topics[parent_index]}, searching through: {parent_topic}\")\n",
    "\n",
    "                for topic in topics_found[:self.spread_constant]:\n",
    "                    queue.append((len(self.visited_topics)-1, topic))\n",
    "                    if topic == self.goal_topic:\n",
    "                        # Rebuilds path back to origin topic\n",
    "                        traversed_topics = [topic, parent_topic]\n",
    "                        while parent_index >= 0:\n",
    "                            traversed_topics.append(self.visited_topics[parent_index])\n",
    "                            parent_index = self.path[parent_index]\n",
    "                        return traversed_topics[::-1]\n",
    "\n",
    "    # Creates BeautifulSoup object from wikipedia link\n",
    "    def make_soup(self, wiki_topic):\n",
    "        html = urlopen(f\"https://en.wikipedia.org/wiki/{wiki_topic}\")\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        return soup\n",
    "\n",
    "    # Finds topics within Wikipedia page\n",
    "    def find_new_topics(self, soup):\n",
    "        topics = []\n",
    "        for link in soup.select('p a[href]'):\n",
    "            href = link['href']\n",
    "            if href.startswith('/wiki/'):\n",
    "                topics.append(href[6:])\n",
    "        return topics\n",
    "\n",
    "    def llm_pick_topics(self, soup):\n",
    "        topic_list = self.find_new_topics(soup)\n",
    "        print(topic_list)\n",
    "        string_list = self.list_to_string(topic_list)\n",
    "        print(string_list)\n",
    "        prompt = self.get_prompt(self.goal_topic, string_list, self.spread_constant)\n",
    "        print(prompt)\n",
    "        response: str = self.llm(prompt=prompt)\n",
    "        print(response)\n",
    "        result = self.list_from_string(response, topic_list)\n",
    "        print(result)\n",
    "        return result\n",
    "\n",
    "    def list_to_string(self, topic_list):\n",
    "        result_string = \"\"\n",
    "        for topic in topic_list:\n",
    "            result_string += str(topic)+\", \"\n",
    "        return result_string[:-2]\n",
    "\n",
    "    def get_prompt(self, goal, string_list, num_of_articles):\n",
    "        prompt: str = f\"\"\"\n",
    "        From the following list of topics [{string_list}], pick up to {num_of_articles} that relate most closely about {goal}.\n",
    "        Your response should include no explanation. The list of topics MUST be formatted in square brackets [] separated by commas.\n",
    "        DO NOT respond in bullet point lists or numbered lists.\n",
    "        The wording of the topics (including the underscores) must be exactly as given.\n",
    "        \"\"\"\n",
    "        return prompt\n",
    "\n",
    "    def list_from_string(self, response, topic_list):\n",
    "        pattern = r\"\\[(.*)\\]\"\n",
    "        match = re.search(pattern, response)\n",
    "        if match:\n",
    "            extracted_text = match.group(1)\n",
    "            extracted_list = [element.strip() for element in extracted_text.split(',')]\n",
    "            result_list = []\n",
    "            for element in extracted_list:\n",
    "                if element in topic_list:\n",
    "                    result_list.append(element)\n",
    "            return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2024-01-30T19:54:46.300064Z",
     "iopub.status.busy": "2024-01-30T19:54:46.299368Z",
     "iopub.status.idle": "2024-01-30T19:54:46.401074Z",
     "shell.execute_reply": "2024-01-30T19:54:46.400177Z",
     "shell.execute_reply.started": "2024-01-30T19:54:46.300029Z"
    },
    "id": "_tECl4Sb1R87",
    "outputId": "dcda7428-2daa-418e-e215-91423bf34926"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'WikiGame' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m game \u001b[38;5;241m=\u001b[39m \u001b[43mWikiGame\u001b[49m(spread_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      2\u001b[0m game\u001b[38;5;241m.\u001b[39mstart_game(llm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'WikiGame' is not defined"
     ]
    }
   ],
   "source": [
    "game = WikiGame(spread_constant=3)\n",
    "game.start_game(llm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OcUzN8nR2RJY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
